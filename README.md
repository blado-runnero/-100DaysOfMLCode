# #100DaysOfMLCode

My attempt for #100DaysOfMLCode.

-----------------------------------


# Day 1:-

I made a charcter recognizer. One of the most exciting project of mine yet. 
This project set the new momentum in my journey. I aimed at making 10 projects, first one is completed in the first day itself. It feels so awesome.

# Learning from today:-

Always make preprocess your data. 

I trained the model and deployed all while my training data was LR and 90 rotated. So I trained again and it correctly classified images this time. 

Link for the same is: https://blado-runnero.github.io/char.html

-----------------------------------

# Day 2:-

Read few medium articles about NLP and why its still a hard problem to solve. ( Hint :- Beacuse of the multiple meaning of the same words, especially in other languages. See this link for more, if you are indian you can understand more easily, https://inshorts.com/en/news/abhi-na-jao-cd-kar-users-claim-song-censored-on-amazon-alexa-1543404865211 )

Took few courses from kaggle, 

1. Pandas (https://www.kaggle.com/learn/pandas)
2. Machine Learning (https://www.kaggle.com/learn/machine-learning)
3. Data Visualization (https://www.kaggle.com/learn/data-visualisation) [half of it, will comlete later]

# Learning from today:-

Since I never really used pandas all by myself, without googling for it, the day felt really productive. We can think of pandas as sql in python, the underlying concept is same. Everytime I was stuck in its exercise, the first thing I thought was, How would I achieve this in sql, and after few trials I would achieve it. But combined with syntax of python, it can be done more elegantly. 

I also learnt how to plot graphs, I can now plot graphs much easily. But for more advanced graph stuff, I would retake this course later. 

I also learned the concept of imputing today, for the first time. And best practice is to impute the whole column with an marker in the name, so that the algorithm can make educated guess by looking both the columns. 

-----------------------------------

# Day 3:-

Today was the day for 2 of the most important models, xgboost and random forests. These are the two of the most used models in any kaggle competitions; dominance is however, of xgboost. 

I didn't wrote a lot of code today, because most of the time was spent understanding these two models. After dedicating a solid 3 hours for this two models also I am yet to gain a solid understanding of these two (I will revisit this topic after few days, this time not by theory, but by a practical implementation, i.e. reading kaggle kernels ), so not much to learn today. 

# Learning from today:-

Ensemble models are great, they have dont useually overfit and if they do, you can easily tune model to overcome that.

# Project Ideas

While I was having a hard time understanding xgboost, so I decided to search for some projct ideas that I can make next. I encountered this two ideas.

1. Estimating the price of a mobile from a feature list. 

2. Face recognition mobile app, by using facenet architecture. (Sounds interesting)

-----------------------------------

# Day 4:-

Today was a light day in terms of ML coding. I worked on my website, yes, from few days from now, I will not be Anshuman Patel anymore, I will become anshumanpatel.in (It already feels so proud to say that my website will be hardcoded and not some wordpress or theme stuff)

Read few kernels from kaggle. Since I am new to kaggle, I am first analyzing the style of different people and analyzing how they approach the problem, and will develop my style seeing them. (Sounds random forest, right?)

# Learning from today:-

EDA is king. (That in itself is a thousand learnings combined.)

